{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Hyperparameters\n",
    "\n",
    "Import [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) from `sklearn` and explore the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so after cleaning the dataset we will going to import the dataset\n",
    "#to do some modelling in it and then we will find the results of our model testing \n",
    "#and training to see which model works in a way that can provide us the highest accurary of the dataset\n",
    "\n",
    "#so in order to run the logistic regression model we first need to import it form\n",
    "#we will first import the model\n",
    "#and then we will look out for the key hyper parameter in the model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#now printing the logistic regression model\n",
    "LogisticRegression()\n",
    "#with all the hyperparameter we only need to tune some of the hyper parameter\n",
    "#rest all can work with the default setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_predict_proba_lr',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_validate_data',\n",
       " 'decision_function',\n",
       " 'densify',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'sparsify']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(LogisticRegression)\n",
    "#important point to noew here is that every logistic model have this fit and predict in it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets understand about the c-hyperparameter ,it is regularization parameter in logistic \n",
    "#regression that control how closely the model fits to the training data\n",
    "\n",
    "#regularization is a technique use to reduce the overfitting of the data\n",
    "\n",
    "#this is important, lets see how C affects the model , it is defined as \n",
    "#C=1/lamda, \n",
    "'''\n",
    "so if lamda tends to 0 then C tends to infinity that means low regularization, high complexity and more likely to overfit the data\n",
    "\n",
    "And if lamba tends to infinity then C tends to 0, that means high regularization,low complexity and more likely to underfit\n",
    "\n",
    "'''\n",
    "#it is also important to note some more parameters of the logistic model that we need to understand\n",
    "\n",
    "'''\n",
    "Sensitivity refers to the probability that the model predicts a positive outcome for an observation when indeed the outcome is positive.\n",
    "\n",
    "Specificity refers to the probability that the model predicts a negative outcome for an observation when indeed the outcome is negative.\n",
    "\n",
    "'''\n",
    "\n",
    "#why need to plot the ROC curve which is the next step in finding the accuracy of the model\n",
    "\n",
    "'''\n",
    "#we are taliking about the ROC curve here\n",
    "One of the most common ways to visualize the sensitivity vs. specificity of a model is by plotting a ROC (Receiver Operating Characteristic) curve, \n",
    "which is a plot of the values of sensitivity vs. 1-specificity as the value of the cut-off point moves from 0 to 1:\n",
    "\n",
    "A model with high sensitivity and high specificity will have a ROC curve that hugs the top left corner of the plot. \n",
    "A model with low sensitivity and low specificity will have a curve that is close to the 45-degree diagonal line.\n",
    "\n",
    "The AUC (area under curve) gives us an idea of how well the model is able to distinguish between positive and negative outcomes.\n",
    "The AUC can range from 0 to 1. The higher the AUC, the better the model is at correctly classifying outcomes.\n",
    "\n",
    "This means that a model with a ROC curve that hugs the top left corner of the plot would have a high area under the curve, and thus be a model that does a good job of correctly classifying outcomes.\n",
    "Conversely, a model with a ROC curve that hugs the 45-degree diagonal line would have a low area under the curve, and thus be a model that does a poor job of classifying outcomes.\n",
    "\n",
    "'''\n",
    "\n",
    "#next we will understand more about the C-statistics\n",
    "\n",
    "'''\n",
    "The c-statistic, also known as the concordance statistic, is equal to to the AUC (area under curve) and has the following interpretations:\n",
    "\n",
    "A value below 0.5 indicates a poor model.\n",
    "A value of 0.5 indicates that the model is no better out classifying outcomes than random chance.\n",
    "The closer the value is to 1, the better the model is at correctly classifying outcomes.\n",
    "A value of 1 means that the model is perfect at classifying outcomes.\n",
    "Thus, a c-statistic gives us an idea about how good a model is at correctly classifying outcomes.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
